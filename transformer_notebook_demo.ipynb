{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3118d062",
   "metadata": {},
   "source": [
    "## Important: Cell Execution Order\n",
    "\n",
    "**This notebook must be executed in sequential order from top to bottom.**\n",
    "\n",
    "Please run each cell in order (you can use Shift+Enter to run each cell). Running cells out of order will result in errors like `NameError: name 'device_encoder' is not defined` because later cells depend on variables defined in earlier cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40301baa",
   "metadata": {},
   "source": [
    "# Large Event Model (LEM) Demo Notebook\n",
    "\n",
    "This notebook demonstrates loading and using the Large Event Model (LEM) for event embeddings and recommendations in smart home environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a78b7c",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's import all the necessary libraries and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2edcdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1dcb79",
   "metadata": {},
   "source": [
    "## 2. Large Event Model (LEM) Definition\n",
    "\n",
    "Let's define the LargeEventModel class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2c0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Large Event Model (LEM)\n",
    "class LargeEventModel(nn.Module):\n",
    "    def __init__(self, input_dim=7, embed_dim=128, num_heads=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        transformer_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
    "        self.output_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input has the right shape\n",
    "        if x.shape[-1] != 7:\n",
    "            # Pad or truncate to 7 features\n",
    "            if x.shape[-1] < 7:\n",
    "                # Pad with zeros\n",
    "                padding = torch.zeros(*x.shape[:-1], 7 - x.shape[-1], device=x.device)\n",
    "                x = torch.cat([x, padding], dim=-1)\n",
    "            else:\n",
    "                # Truncate\n",
    "                x = x[..., :7]\n",
    "                \n",
    "        x = self.input_proj(x)\n",
    "        embeddings = self.transformer_encoder(x)\n",
    "        pooled_embedding = embeddings.mean(dim=1)\n",
    "        return self.output_proj(pooled_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76634e",
   "metadata": {},
   "source": [
    "## 3. Load Encoders and Define Preprocessing Functions\n",
    "\n",
    "### Theory: Understanding the Encoders\n",
    "\n",
    "In smart home event modeling, we need to convert categorical data (like device names, capabilities, and states) into numerical representations that machine learning models can process. Our Large Event Model (LEM) uses three key encoders:\n",
    "\n",
    "#### 1. Device Encoder\n",
    "The device encoder converts device names (e.g., \"smart_light\", \"smart_thermostat\") into integer indices. This encoder was created by:\n",
    "1. Extracting all unique device names from the training dataset\n",
    "2. Sorting them alphabetically to ensure consistent encoding\n",
    "3. Using scikit-learn's `LabelEncoder` to assign an integer index (0, 1, 2, etc.) to each device name\n",
    "\n",
    "#### 2. Capability Encoder\n",
    "The capability encoder converts device capabilities (e.g., \"power\", \"temperature_control\") into integer indices. Each device has specific capabilities which represent what the device can do. For example, a smart light has \"power\" and \"brightness_control\" capabilities.\n",
    "\n",
    "The capabilities were also organized into semantic groups like \"thermal\", \"mechanical\", \"audio\", \"visual\", and \"security\" using a mapping dictionary:\n",
    "```python\n",
    "capability_to_group = {\n",
    "    'temperature_control': 'thermal',\n",
    "    'door_status': 'mechanical',\n",
    "    'power': 'mechanical',\n",
    "    'incoming_call': 'audio',\n",
    "    'volume_control': 'audio',\n",
    "    'brightness_control': 'visual',\n",
    "    # and so on...\n",
    "}\n",
    "```\n",
    "\n",
    "This grouping is based on a knowledge graph of how devices typically interact in a smart home environment. Similar controls belonging to certain similar groups were given higher weights during the model training process. For example, \"thermal\" controls like \"temperature_control\" and \"humidity_control\" have a stronger correlation with each other than with unrelated capabilities like \"audio\" controls.\n",
    "\n",
    "During the embedding process, capabilities within the same group receive boosted attention weights in the LEM's self-attention mechanism. This approach leverages domain knowledge about smart home systems to improve the model's understanding of related actions. For instance, when a user adjusts the thermostat temperature, the model can more confidently predict related actions like adjusting the humidity level, since both are in the \"thermal\" group and often controlled together.\n",
    "\n",
    "This semantic grouping enables the LEM to capture not just statistical correlations in the data, but also real-world relationships between devices and their functions, resulting in more intuitive and contextually appropriate recommendations.\n",
    "\n",
    "#### 3. State Encoder\n",
    "The state encoder converts device states (e.g., \"ON\", \"OFF\", \"WARM\") into integer indices. States represent the current condition of a device's capability. For example, the \"power\" capability might have states like \"ON\" or \"OFF\".\n",
    "\n",
    "### Creation Process\n",
    "\n",
    "All encoders were created with this process:\n",
    "1. The `train_encoders.py` script analyzed the event dataset to gather all unique categories\n",
    "2. For each category (devices, capabilities, states), a set was built to ensure uniqueness\n",
    "3. Each set was converted to a sorted list to ensure deterministic encoder behavior\n",
    "4. Each list was fitted to a scikit-learn `LabelEncoder` which maps strings to integers\n",
    "5. The encoders were saved to disk using joblib for later use\n",
    "\n",
    "```python\n",
    "# From train_encoders.py\n",
    "# Create encoders\n",
    "device_encoder = LabelEncoder().fit(sorted(list(devices)))\n",
    "capability_encoder = LabelEncoder().fit(sorted(list(capabilities)))\n",
    "state_encoder = LabelEncoder().fit(sorted(list(states)))\n",
    "```\n",
    "\n",
    "### LEM Model Training Process\n",
    "\n",
    "The Large Event Model (LEM) file (`transformer_model.pt`) was created through a multi-step training process:\n",
    "\n",
    "1. **Data Preparation**: The raw event data from `event_dataset.json` was first processed using the encoders mentioned above, converting categorical data like device names, capabilities, and states into numerical vectors suitable for machine learning.\n",
    "\n",
    "2. **Model Architecture**: The LEM uses a transformer-based architecture, specifically utilizing PyTorch's `TransformerEncoder` with self-attention mechanisms. This architecture was chosen for its ability to capture complex relationships between events in a sequence.\n",
    "\n",
    "3. **Feature Engineering**: Each event was transformed into a 7-dimensional feature vector consisting of:\n",
    "   - Encoded device (integer)\n",
    "   - Encoded capability (integer)\n",
    "   - Encoded state (integer)\n",
    "   - Time-of-day features (hour, minute)\n",
    "   - Day-of-week (normalized to [0,1])\n",
    "   - A bias term (1.0)\n",
    "\n",
    "4. **Training Objective**: The model was trained to learn meaningful embeddings of event sequences by predicting future events in a sequence given past events, using a combination of contrastive learning and sequence prediction objectives.\n",
    "\n",
    "5. **Hyperparameter Tuning**: The model was fine-tuned with 4 attention heads, 2 transformer layers, and an embedding dimension of 128, which provided the optimal balance between model capacity and inference speed.\n",
    "\n",
    "6. **Capability Group Weighting**: During training, events with capabilities in the same semantic group received boosted attention weights, encouraging the model to learn the domain-specific relationships between similar capabilities.\n",
    "\n",
    "7. **Model Serialization**: After training, the optimized model parameters were saved to `transformer_model.pt` using PyTorch's `torch.save()` function, allowing the model to be loaded and used for inference without requiring retraining.\n",
    "\n",
    "The resulting LEM model combines the strengths of transformer architectures with domain-specific knowledge about smart home environments, enabling it to efficiently capture both temporal patterns and semantic relationships in user interactions with smart devices.\n",
    "\n",
    "These encoders are crucial for the LEM's operation as they convert textual event data into the numerical format required for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e65c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: ['ac_unit' 'fridge' 'smart_light' 'smart_lock' 'smart_tv' 'smartphone'\n",
      " 'washer']\n",
      "\n",
      "Available capabilities: ['brightness_control' 'door_status' 'incoming_call' 'lock_control' 'power'\n",
      " 'temperature_control' 'volume_control']\n",
      "\n",
      "Available states: ['BRIGHT' 'CALL_RECEIVED' 'COOL_HIGH' 'COOL_MEDIUM' 'DIM' 'ENERGY_SAVER'\n",
      " 'HIGH' 'LOCKED' 'LOW' 'MEDIUM' 'MUTE' 'NO_CALL' 'OFF' 'ON' 'OPEN'\n",
      " 'UNLOCKED']\n"
     ]
    }
   ],
   "source": [
    "# Load encoders\n",
    "device_encoder = joblib.load('device_encoder.pkl')\n",
    "capability_encoder = joblib.load('capability_encoder.pkl')\n",
    "state_encoder = joblib.load('state_encoder.pkl')\n",
    "\n",
    "print(\"Available devices:\", device_encoder.classes_)\n",
    "print(\"\\nAvailable capabilities:\", capability_encoder.classes_)\n",
    "print(\"\\nAvailable states:\", state_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218bb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess a single event\n",
    "def preprocess_event(event):\n",
    "    \"\"\"Convert event data to numerical features using encoders\"\"\"\n",
    "    try:\n",
    "        # Try to encode with existing encoders\n",
    "        device = device_encoder.transform([event[\"device\"]])[0]\n",
    "        capability = capability_encoder.transform([event[\"capability\"]])[0]\n",
    "        state = state_encoder.transform([event[\"attributes\"][\"state\"]])[0]\n",
    "        \n",
    "        # Create feature vector\n",
    "        features = [\n",
    "            device, capability, state,\n",
    "            # Add time-based features\n",
    "            float(datetime.fromisoformat(event[\"timestamp\"]).hour) / 24.0,\n",
    "            float(datetime.fromisoformat(event[\"timestamp\"]).minute) / 60.0,\n",
    "            float(datetime.fromisoformat(event[\"timestamp\"]).weekday()) / 7.0,\n",
    "            1.0  # Bias term\n",
    "        ]\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32)\n",
    "    except (ValueError, KeyError) as e:\n",
    "        print(f\"\\nWarning: Encountered unknown label: {str(e)}\")\n",
    "        print(\"Using fallback encoding for unknown values.\")\n",
    "        \n",
    "        # Use fallback values for unknown labels\n",
    "        device_val = 0  # Default to first device\n",
    "        capability_val = 0  # Default to first capability\n",
    "        state_val = 0  # Default to first state\n",
    "        \n",
    "        # Try to encode known values\n",
    "        try:\n",
    "            if event[\"device\"] in device_encoder.classes_:\n",
    "                device_val = device_encoder.transform([event[\"device\"]])[0]\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            if event[\"capability\"] in capability_encoder.classes_:\n",
    "                capability_val = capability_encoder.transform([event[\"capability\"]])[0]\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            if event[\"attributes\"][\"state\"] in state_encoder.classes_:\n",
    "                state_val = state_encoder.transform([event[\"attributes\"][\"state\"]])[0]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Create feature vector with fallback values\n",
    "        features = [\n",
    "            device_val, capability_val, state_val,\n",
    "            # Add time-based features\n",
    "            float(datetime.fromisoformat(event[\"timestamp\"]).hour) / 24.0,\n",
    "            float(datetime.fromisoformat(event[\"timestamp\"]).minute) / 60.0,\n",
    "            float(datetime.fromisoformat(event[\"timestamp\"]).weekday()) / 7.0,\n",
    "            1.0  # Bias term\n",
    "        ]\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "# Function to get embedding from events\n",
    "def get_event_embedding(events, model):\n",
    "    \"\"\"Process a sequence of events and return their embedding\"\"\"\n",
    "    # Preprocess each event\n",
    "    processed = [preprocess_event(event) for event in events]\n",
    "    \n",
    "    # Stack the tensors\n",
    "    if processed:\n",
    "        tensor_input = torch.stack(processed).unsqueeze(0)\n",
    "    else:\n",
    "        return torch.zeros((1, 128), dtype=torch.float32)  # Default size\n",
    "    \n",
    "    # Get embedding from model\n",
    "    with torch.no_grad():\n",
    "        embedding = model(tensor_input)\n",
    "    return embedding\n",
    "\n",
    "# Function to time inference\n",
    "def time_inference(events, model, num_runs=10):\n",
    "    \"\"\"Measure inference time for a sequence of events\"\"\"\n",
    "    # Warm-up run\n",
    "    _ = get_event_embedding(events, model)\n",
    "    \n",
    "    # Timed runs\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        _ = get_event_embedding(events, model)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_runs\n",
    "    return avg_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3f34e",
   "metadata": {},
   "source": [
    "## 4. Load Large Event Model (LEM) and Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc64ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Large Event Model (LEM)\n",
      "Loaded historical embeddings (shape: torch.Size([2275, 1, 128])) and 2275 actions\n"
     ]
    }
   ],
   "source": [
    "# Load the LEM model\n",
    "model = LargeEventModel(input_dim=7, embed_dim=128)\n",
    "model.load_state_dict(torch.load('transformer_model.pt'))\n",
    "model.eval()\n",
    "print(\"Loaded Large Event Model (LEM)\")\n",
    "\n",
    "# Load saved embeddings and actions\n",
    "historical_embeddings = torch.load('transformer_embeddings.pt')\n",
    "with open('transformer_actions.json', 'r') as f:\n",
    "    historical_actions = json.load(f)\n",
    "print(f\"Loaded historical embeddings (shape: {historical_embeddings.shape}) and {len(historical_actions)} actions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e3404",
   "metadata": {},
   "source": [
    "## 5. Load Event Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4a62b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 500 event sequences\n",
      "First sequence contains 1144 events\n",
      "\n",
      "Sample events:\n",
      "\n",
      "Event 1:\n",
      "  Device: washer\n",
      "  Capability: power\n",
      "  State: ON\n",
      "  Timestamp: 2025-02-09T01:44:08.469019Z\n",
      "\n",
      "Event 2:\n",
      "  Device: smart_tv\n",
      "  Capability: volume_control\n",
      "  State: LOW\n",
      "  Timestamp: 2025-02-09T01:45:08.469019Z\n",
      "\n",
      "Event 3:\n",
      "  Device: ac_unit\n",
      "  Capability: temperature_control\n",
      "  State: ENERGY_SAVER\n",
      "  Timestamp: 2025-02-09T01:49:08.469019Z\n"
     ]
    }
   ],
   "source": [
    "# Load event dataset\n",
    "with open('event_dataset.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Display first sequence and first few events\n",
    "print(f\"Dataset contains {len(dataset)} event sequences\")\n",
    "print(f\"First sequence contains {len(dataset[0])} events\")\n",
    "print(\"\\nSample events:\")\n",
    "for i, event in enumerate(dataset[0][:3]):\n",
    "    print(f\"\\nEvent {i+1}:\")\n",
    "    print(f\"  Device: {event['device']}\")\n",
    "    print(f\"  Capability: {event['capability']}\")\n",
    "    print(f\"  State: {event['attributes']['state']}\")\n",
    "    print(f\"  Timestamp: {event['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01fd40",
   "metadata": {},
   "source": [
    "## 6. Find Similar Actions Based on Event Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fd1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference time for sample sequence...\n",
      "Average inference time over 50 runs: 1.37 ms\n",
      "Sample sequence embedding shape: torch.Size([1, 128])\n",
      "\n",
      "Context events:\n",
      "\n",
      "Event 1:\n",
      "  Device: smartphone\n",
      "  Capability: incoming_call\n",
      "  State: NO_CALL\n",
      "\n",
      "Event 2:\n",
      "  Device: smartphone\n",
      "  Capability: incoming_call\n",
      "  State: CALL_RECEIVED\n",
      "\n",
      "Event 3:\n",
      "  Device: smart_tv\n",
      "  Capability: volume_control\n",
      "  State: MUTE\n",
      "\n",
      "Event 4:\n",
      "  Device: smart_lock\n",
      "  Capability: lock_control\n",
      "  State: LOCKED\n",
      "\n",
      "Event 5:\n",
      "  Device: smart_light\n",
      "  Capability: brightness_control\n",
      "  State: OFF\n",
      "\n",
      "Recommended actions:\n",
      "\n",
      "Recommendation 1 (similarity: 0.9999):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n",
      "\n",
      "Recommendation 2 (similarity: 0.9993):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: on\n",
      "\n",
      "Recommendation 3 (similarity: 0.9991):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n"
     ]
    }
   ],
   "source": [
    "# Function to find similar actions based on embeddings\n",
    "def find_similar_actions(embedding, historical_embeddings, historical_actions, top_n=3):\n",
    "    \"\"\"Find the most similar actions based on embedding similarity\"\"\"\n",
    "    # Convert to numpy for simplicity\n",
    "    if isinstance(embedding, torch.Tensor):\n",
    "        # Remove batch dimension if present\n",
    "        if len(embedding.shape) > 1 and embedding.shape[0] == 1:\n",
    "            embedding = embedding.squeeze(0)\n",
    "        # Convert to numpy array\n",
    "        embedding_np = embedding.detach().cpu().numpy()\n",
    "    else:\n",
    "        embedding_np = embedding\n",
    "    \n",
    "    if isinstance(historical_embeddings, torch.Tensor):\n",
    "        historical_embeddings_np = historical_embeddings.detach().cpu().numpy()\n",
    "    else:\n",
    "        historical_embeddings_np = historical_embeddings\n",
    "    \n",
    "    # Handle 3D historical embeddings\n",
    "    if len(historical_embeddings_np.shape) == 3:\n",
    "        # Reshape (n, 1, d) to (n, d)\n",
    "        historical_embeddings_np = historical_embeddings_np.squeeze(1)\n",
    "    \n",
    "    # Ensure both are 2D arrays\n",
    "    if len(embedding_np.shape) == 1:\n",
    "        embedding_np = embedding_np.reshape(1, -1)\n",
    "    \n",
    "    # Compute dot product\n",
    "    dot_product = np.dot(embedding_np, historical_embeddings_np.T)\n",
    "    \n",
    "    # Compute norms\n",
    "    embedding_norm = np.linalg.norm(embedding_np, axis=1)\n",
    "    historical_norm = np.linalg.norm(historical_embeddings_np, axis=1)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = dot_product / (embedding_norm.reshape(-1, 1) * historical_norm)\n",
    "    similarity = similarity.flatten()  # Ensure it's a flat array\n",
    "    \n",
    "    # Get top indices\n",
    "    top_indices = np.argsort(similarity)[-top_n:][::-1]\n",
    "    \n",
    "    # Get corresponding actions and similarities\n",
    "    top_actions = [historical_actions[i] for i in top_indices]\n",
    "    top_similarities = [similarity[i] for i in top_indices]\n",
    "    \n",
    "    return list(zip(top_actions, top_similarities))\n",
    "\n",
    "# Get a sample sequence\n",
    "recent_events = dataset[0][-5:]  # Last 5 events from first sequence\n",
    "\n",
    "# Get embedding and measure inference time\n",
    "print(\"Measuring inference time for sample sequence...\")\n",
    "inference_time = time_inference(recent_events, model, num_runs=50)\n",
    "print(f\"Average inference time over 50 runs: {inference_time*1000:.2f} ms\")\n",
    "\n",
    "# Get embedding\n",
    "embedding = get_event_embedding(recent_events, model)\n",
    "print(\"Sample sequence embedding shape:\", embedding.shape)\n",
    "\n",
    "# Find similar actions\n",
    "similar_actions = find_similar_actions(embedding, historical_embeddings, historical_actions, top_n=3)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nContext events:\")\n",
    "for i, event in enumerate(recent_events):\n",
    "    print(f\"\\nEvent {i+1}:\")\n",
    "    print(f\"  Device: {event['device']}\")\n",
    "    print(f\"  Capability: {event['capability']}\")\n",
    "    print(f\"  State: {event['attributes']['state']}\")\n",
    "\n",
    "print(\"\\nRecommended actions:\")\n",
    "for i, (action, similarity) in enumerate(similar_actions):\n",
    "    print(f\"\\nRecommendation {i+1} (similarity: {similarity:.4f}):\")\n",
    "    for key, value in action.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b25e2",
   "metadata": {},
   "source": [
    "## 7. Example Events for Custom Testing\n",
    "\n",
    "Below are several example events that you can copy and paste to create custom event sequences. These cover different device types and scenarios:\n",
    "\n",
    "### Morning Routine Events\n",
    "```python\n",
    "morning_events = [\n",
    "    {\n",
    "        \"device\": \"smart_light\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"ON\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_thermostat\",\n",
    "        \"capability\": \"temperature_control\",\n",
    "        \"attributes\": {\"state\": \"WARM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"ON\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Evening Routine Events\n",
    "```python\n",
    "evening_events = [\n",
    "    {\n",
    "        \"device\": \"smart_light\",\n",
    "        \"capability\": \"brightness_control\",\n",
    "        \"attributes\": {\"state\": \"DIM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_thermostat\",\n",
    "        \"capability\": \"temperature_control\",\n",
    "        \"attributes\": {\"state\": \"WARM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_lock\",\n",
    "        \"capability\": \"lock_control\",\n",
    "        \"attributes\": {\"state\": \"LOCKED\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Security Events\n",
    "```python\n",
    "security_events = [\n",
    "    {\n",
    "        \"device\": \"smart_lock\",\n",
    "        \"capability\": \"lock_control\",\n",
    "        \"attributes\": {\"state\": \"LOCKED\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_light\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"OFF\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smartphone\",\n",
    "        \"capability\": \"app_usage\",\n",
    "        \"attributes\": {\"state\": \"ACTIVE\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Entertainment Events\n",
    "```python\n",
    "entertainment_events = [\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"ON\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"volume_control\",\n",
    "        \"attributes\": {\"state\": \"LOUD\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_light\",\n",
    "        \"capability\": \"brightness_control\",\n",
    "        \"attributes\": {\"state\": \"DIM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Cross-Device Interaction Events\n",
    "\n",
    "#### 1. Incoming Call During TV Watching\n",
    "```python\n",
    "call_tv_events = [\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"ON\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"volume_control\",\n",
    "        \"attributes\": {\"state\": \"MEDIUM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smartphone\",\n",
    "        \"capability\": \"incoming_call\",\n",
    "        \"attributes\": {\"state\": \"ACTIVE\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "#### 2. Home Arrival Sequence\n",
    "```python\n",
    "arrival_events = [\n",
    "    {\n",
    "        \"device\": \"smart_lock\",\n",
    "        \"capability\": \"lock_control\",\n",
    "        \"attributes\": {\"state\": \"UNLOCKED\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_light\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"ON\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_thermostat\",\n",
    "        \"capability\": \"temperature_control\",\n",
    "        \"attributes\": {\"state\": \"WARM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "#### 3. Movie Night Preparation\n",
    "```python\n",
    "movie_night_events = [\n",
    "    {\n",
    "        \"device\": \"smart_light\",\n",
    "        \"capability\": \"brightness_control\",\n",
    "        \"attributes\": {\"state\": \"DIM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"ON\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smartphone\",\n",
    "        \"capability\": \"app_usage\",\n",
    "        \"attributes\": {\"state\": \"INACTIVE\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_thermostat\",\n",
    "        \"capability\": \"temperature_control\",\n",
    "        \"attributes\": {\"state\": \"WARM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "#### 4. Sleeping Routine\n",
    "```python\n",
    "sleeping_events = [\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"OFF\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_light\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"OFF\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_lock\",\n",
    "        \"capability\": \"lock_control\",\n",
    "        \"attributes\": {\"state\": \"LOCKED\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smartphone\",\n",
    "        \"capability\": \"app_usage\",\n",
    "        \"attributes\": {\"state\": \"INACTIVE\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4f579",
   "metadata": {},
   "source": [
    "## 8. Create Custom Events and Get Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625026ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference time for custom events...\n",
      "Average inference time over 50 runs: 1.11 ms\n",
      "Single inference time: 1.04 ms\n",
      "\n",
      "Custom Event Sequence:\n",
      "\n",
      "Event 1:\n",
      "  Device: smart_light\n",
      "  Capability: power\n",
      "  State: ON\n",
      "\n",
      "Event 2:\n",
      "  Device: ac_unit\n",
      "  Capability: temperature_control\n",
      "  State: COOL_MEDIUM\n",
      "\n",
      "Event 3:\n",
      "  Device: smartphone\n",
      "  Capability: incoming_call\n",
      "  State: CALL_RECEIVED\n",
      "\n",
      "Recommended actions based on custom events:\n",
      "\n",
      "Recommendation 1 (similarity: 0.9961):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n",
      "\n",
      "Recommendation 2 (similarity: 0.9956):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n",
      "\n",
      "Recommendation 3 (similarity: 0.9955):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n",
      "\n",
      "Recommendation 4 (similarity: 0.9955):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n",
      "\n",
      "Recommendation 5 (similarity: 0.9945):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n"
     ]
    }
   ],
   "source": [
    "# Helper function to create event from user input\n",
    "def create_custom_event(device, capability, state):\n",
    "    return {\n",
    "        \"device\": device,\n",
    "        \"capability\": capability,\n",
    "        \"attributes\": {\"state\": state},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "# Create a custom event sequence (example)\n",
    "custom_events = [\n",
    "    create_custom_event(\"smart_light\", \"power\", \"ON\"),\n",
    "    create_custom_event(\"ac_unit\", \"temperature_control\", \"COOL_MEDIUM\"),  # Fixed values\n",
    "    create_custom_event(\"smartphone\", \"incoming_call\", \"CALL_RECEIVED\"),  # Fixed values\n",
    "]\n",
    "\n",
    "# Get embedding for custom events and measure inference time\n",
    "print(\"Measuring inference time for custom events...\")\n",
    "inference_time = time_inference(custom_events, model, num_runs=50)\n",
    "print(f\"Average inference time over 50 runs: {inference_time*1000:.2f} ms\")\n",
    "\n",
    "# Get embedding\n",
    "start_time = time.time()\n",
    "custom_embedding = get_event_embedding(custom_events, model)\n",
    "end_time = time.time()\n",
    "print(f\"Single inference time: {(end_time - start_time)*1000:.2f} ms\")\n",
    "\n",
    "# Find similar actions\n",
    "similar_actions = find_similar_actions(custom_embedding, historical_embeddings, historical_actions, top_n=5)\n",
    "\n",
    "# Display the custom events\n",
    "print(\"\\nCustom Event Sequence:\")\n",
    "for i, event in enumerate(custom_events):\n",
    "    print(f\"\\nEvent {i+1}:\")\n",
    "    print(f\"  Device: {event['device']}\")\n",
    "    print(f\"  Capability: {event['capability']}\")\n",
    "    print(f\"  State: {event['attributes']['state']}\")\n",
    "\n",
    "# Display recommended actions\n",
    "print(\"\\nRecommended actions based on custom events:\")\n",
    "for i, (action, similarity) in enumerate(similar_actions):\n",
    "    print(f\"\\nRecommendation {i+1} (similarity: {similarity:.4f}):\")\n",
    "    for key, value in action.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00706f8",
   "metadata": {},
   "source": [
    "### Testing Cross-Device Scenarios\n",
    "\n",
    "Let's test one of our cross-device scenarios to see how the model recommends actions based on interactions across multiple appliances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6d515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference time for cross-device scenario...\n",
      "Average inference time over 20 runs: 4.36 ms\n",
      "Single inference time: 27.57 ms\n",
      "\n",
      "Cross-Device Event Sequence (Incoming Call During TV Watching):\n",
      "\n",
      "Event 1:\n",
      "  Device: smart_tv\n",
      "  Capability: power\n",
      "  State: ON\n",
      "\n",
      "Event 2:\n",
      "  Device: smart_tv\n",
      "  Capability: volume_control\n",
      "  State: MEDIUM\n",
      "\n",
      "Event 3:\n",
      "  Device: smartphone\n",
      "  Capability: incoming_call\n",
      "  State: CALL_RECEIVED\n",
      "\n",
      "Recommended actions based on cross-device events:\n",
      "\n",
      "Recommendation 1 (similarity: 0.9947):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: on\n",
      "\n",
      "Recommendation 2 (similarity: 0.9947):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n",
      "\n",
      "Recommendation 3 (similarity: 0.9946):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: on\n",
      "\n",
      "Recommendation 4 (similarity: 0.9946):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n",
      "\n",
      "Recommendation 5 (similarity: 0.9946):\n",
      "  device: smart_light\n",
      "  capability: power\n",
      "  state: off\n"
     ]
    }
   ],
   "source": [
    "# Example: Incoming Call During TV Watching\n",
    "call_tv_events = [\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"power\",\n",
    "        \"attributes\": {\"state\": \"ON\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smart_tv\",\n",
    "        \"capability\": \"volume_control\",\n",
    "        \"attributes\": {\"state\": \"MEDIUM\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"device\": \"smartphone\",\n",
    "        \"capability\": \"incoming_call\",\n",
    "        \"attributes\": {\"state\": \"CALL_RECEIVED\"},\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "]\n",
    "\n",
    "# Measure inference time\n",
    "print(\"Measuring inference time for cross-device scenario...\")\n",
    "inference_time = time_inference(call_tv_events, model, num_runs=20)\n",
    "print(f\"Average inference time over 20 runs: {inference_time*1000:.2f} ms\")\n",
    "\n",
    "# Get embedding\n",
    "start_time = time.time()\n",
    "cross_device_embedding = get_event_embedding(call_tv_events, model)\n",
    "end_time = time.time()\n",
    "print(f\"Single inference time: {(end_time - start_time)*1000:.2f} ms\")\n",
    "\n",
    "# Find similar actions\n",
    "similar_actions = find_similar_actions(cross_device_embedding, historical_embeddings, historical_actions, top_n=5)\n",
    "\n",
    "# Display the cross-device events\n",
    "print(\"\\nCross-Device Event Sequence (Incoming Call During TV Watching):\")\n",
    "for i, event in enumerate(call_tv_events):\n",
    "    print(f\"\\nEvent {i+1}:\")\n",
    "    print(f\"  Device: {event['device']}\")\n",
    "    print(f\"  Capability: {event['capability']}\")\n",
    "    print(f\"  State: {event['attributes']['state']}\")\n",
    "\n",
    "# Display recommended actions\n",
    "print(\"\\nRecommended actions based on cross-device events:\")\n",
    "for i, (action, similarity) in enumerate(similar_actions):\n",
    "    print(f\"\\nRecommendation {i+1} (similarity: {similarity:.4f}):\")\n",
    "    for key, value in action.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# The model should understand the context of a TV being on and a call coming in,\n",
    "# potentially recommending actions like pausing content, lowering volume, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32796e",
   "metadata": {},
   "source": [
    "## 9. Benchmark Different Event Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6087b23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking inference time for different sequence lengths...\n",
      "Sequence length 1: 0.62 ms (average over 20 runs)\n",
      "Sequence length 2: 1.09 ms (average over 20 runs)\n",
      "Sequence length 3: 1.08 ms (average over 20 runs)\n",
      "Sequence length 5: 1.25 ms (average over 20 runs)\n",
      "Sequence length 10: 1.85 ms (average over 20 runs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define different event sequence lengths to test\n",
    "sequence_lengths = [1, 2, 3, 5, 10]\n",
    "\n",
    "# Function to run timing benchmark\n",
    "def benchmark_sequence_lengths(lengths, num_runs=20):\n",
    "    results = []\n",
    "    \n",
    "    for length in lengths:\n",
    "        if length <= len(dataset[0]):\n",
    "            # Get events from the dataset\n",
    "            events = dataset[0][:length]\n",
    "            \n",
    "            # Time inference\n",
    "            time_ms = time_inference(events, model, num_runs=num_runs) * 1000\n",
    "            results.append((length, time_ms))\n",
    "            print(f\"Sequence length {length}: {time_ms:.2f} ms (average over {num_runs} runs)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmark\n",
    "print(\"Benchmarking inference time for different sequence lengths...\")\n",
    "benchmark_results = benchmark_sequence_lengths(sequence_lengths)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "lengths, times = zip(*benchmark_results)\n",
    "plt.plot(lengths, times, marker='o', linestyle='-', linewidth=2)\n",
    "plt.title('LEM Inference Time vs Sequence Length')\n",
    "plt.xlabel('Number of Events in Sequence')\n",
    "plt.ylabel('Inference Time (ms)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbebecdd",
   "metadata": {},
   "source": [
    "## 10. Compare with LLM\n",
    "\n",
    "In this section, we'll compare our Large Event Model (LEM)'s performance with a Large Language Model (LLM) - specifically a Llama model from Hugging Face. We'll compare both inference time and the quality of recommendations without providing any additional prompting to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44b25ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading meta-llama/Llama-2-7b-chat-hf...\n",
      "Error loading the LLM: You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf.\n",
      "401 Client Error. (Request ID: Root=1-67dcef2e-5c5c01385ec3126f1408e5a3;3a0a8a2e-08c5-41a8-a38b-89bb7bf16f73)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\n",
      "Access to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
      "\n",
      "Fallback: Using a smaller open model that doesn't require authentication...\n",
      "Error loading fallback model: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`\n",
      "Please install the transformers library with 'pip install transformers' or set up Hugging Face access.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for Llama model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Helper function to format events into a prompt for the LLM\n",
    "def format_events_for_llm(events):\n",
    "    \"\"\"Convert event data to a text prompt for the LLM\"\"\"\n",
    "    prompt = \"Smart home events:\\n\"\n",
    "    \n",
    "    for i, event in enumerate(events):\n",
    "        prompt += f\"{i+1}. Device: {event['device']}, \"\n",
    "        prompt += f\"Capability: {event['capability']}, \"\n",
    "        prompt += f\"State: {event['attributes']['state']}\\n\"\n",
    "    \n",
    "    prompt += \"\\nRecommended next actions:\"\n",
    "    return prompt\n",
    "\n",
    "# Set up the Llama model with low precision to save memory\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "try:\n",
    "    # Try to load a smaller variant of Llama to save memory\n",
    "    model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # Can be changed to other variants\n",
    "    \n",
    "    print(f\"Loading {model_name}...\")\n",
    "    # Load with lower precision to save memory\n",
    "    llm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,  # Use half precision\n",
    "        device_map=\"auto\",\n",
    "        load_in_8bit=True,  # Further quantize to save memory\n",
    "    )\n",
    "    print(f\"Successfully loaded {model_name}\")\n",
    "    \n",
    "    # Check if Hugging Face token is set\n",
    "    if os.environ.get(\"HF_TOKEN\") is None:\n",
    "        print(\"Note: You may need to set the HF_TOKEN environment variable to access gated models.\")\n",
    "        print(\"You can get a token from https://huggingface.co/settings/tokens\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the LLM: {str(e)}\")\n",
    "    print(\"\\nFallback: Using a smaller open model that doesn't require authentication...\")\n",
    "    \n",
    "    # Fallback to a smaller open model\n",
    "    try:\n",
    "        model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "        llm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        print(f\"Successfully loaded fallback model: {model_name}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error loading fallback model: {str(e2)}\")\n",
    "        print(\"Please install the transformers library with 'pip install transformers' or set up Hugging Face access.\")\n",
    "        llm_model = None\n",
    "        llm_tokenizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c6e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get LLM inference on events\n",
    "def llm_inference(events, tokenizer, model, max_new_tokens=100):\n",
    "    \"\"\"Get LLM inference for a sequence of events\"\"\"\n",
    "    if tokenizer is None or model is None:\n",
    "        return \"LLM model not loaded\", 0\n",
    "    \n",
    "    # Format the events as a prompt\n",
    "    prompt = format_events_for_llm(events)\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    # Decode the output\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the part after our prompt\n",
    "    if prompt in response:\n",
    "        response = response[len(prompt):]\n",
    "    \n",
    "    return response, inference_time\n",
    "\n",
    "# Function to time LLM inference\n",
    "def time_llm_inference(events, tokenizer, model, num_runs=3):\n",
    "    \"\"\"Measure average LLM inference time for a sequence of events\"\"\"\n",
    "    if tokenizer is None or model is None:\n",
    "        return 0\n",
    "    \n",
    "    total_time = 0\n",
    "    \n",
    "    # Do fewer runs since LLM inference is much slower\n",
    "    for _ in range(num_runs):\n",
    "        _, inference_time = llm_inference(events, tokenizer, model)\n",
    "        total_time += inference_time\n",
    "    \n",
    "    avg_time = total_time / num_runs\n",
    "    return avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ad76ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipping LLM comparison as the model could not be loaded.\n",
      "To run the comparison, make sure you have installed the transformers library\n",
      "and have access to Hugging Face models.\n"
     ]
    }
   ],
   "source": [
    "# Test the LLM with the same custom events\n",
    "if llm_model is not None and llm_tokenizer is not None:\n",
    "    print(\"\\n--- Comparing Large Event Model (LEM) with LLM ---\\n\")\n",
    "    \n",
    "    # Using the same custom events from before\n",
    "    print(\"Custom Event Sequence:\")\n",
    "    for i, event in enumerate(custom_events):\n",
    "        print(f\"\\nEvent {i+1}:\")\n",
    "        print(f\"  Device: {event['device']}\")\n",
    "        print(f\"  Capability: {event['capability']}\")\n",
    "        print(f\"  State: {event['attributes']['state']}\")\n",
    "    \n",
    "    # LLM inference time - Just one run since it's much slower\n",
    "    print(\"\\nMeasuring LLM inference time...\")\n",
    "    llm_avg_time = time_llm_inference(custom_events, llm_tokenizer, llm_model, num_runs=1)\n",
    "    print(f\"LLM inference time: {llm_avg_time*1000:.2f} ms\")\n",
    "    \n",
    "    # LEM model time (from earlier)\n",
    "    lem_time = inference_time\n",
    "    print(f\"LEM inference time: {lem_time*1000:.2f} ms\")\n",
    "    print(f\"Speed difference: LLM is {llm_avg_time/lem_time:.1f}x slower\")\n",
    "    \n",
    "    # Get LLM response\n",
    "    print(\"\\nGenerating LLM response...\")\n",
    "    llm_response, _ = llm_inference(custom_events, llm_tokenizer, llm_model)\n",
    "    \n",
    "    # Display LLM recommendations\n",
    "    print(\"\\nLLM recommendations (raw output):\")\n",
    "    print(llm_response)\n",
    "    \n",
    "    # Reminder of LEM model recommendations\n",
    "    print(\"\\nLEM recommendations (from earlier):\")\n",
    "    for i, (action, similarity) in enumerate(similar_actions[:3]):  # Show just top 3\n",
    "        print(f\"\\nRecommendation {i+1} (similarity: {similarity:.4f}):\")\n",
    "        for key, value in action.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"\\nSkipping LLM comparison as the model could not be loaded.\")\n",
    "    print(\"To run the comparison, make sure you have installed the transformers library\")\n",
    "    print(\"and have access to Hugging Face models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9adfe7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM with the cross-device scenario\n",
    "if llm_model is not None and llm_tokenizer is not None:\n",
    "    print(\"\\n--- Comparing with Cross-Device Scenario ---\\n\")\n",
    "    \n",
    "    # Using the call_tv_events from earlier\n",
    "    print(\"Cross-Device Event Sequence (Incoming Call During TV Watching):\")\n",
    "    for i, event in enumerate(call_tv_events):\n",
    "        print(f\"\\nEvent {i+1}:\")\n",
    "        print(f\"  Device: {event['device']}\")\n",
    "        print(f\"  Capability: {event['capability']}\")\n",
    "        print(f\"  State: {event['attributes']['state']}\")\n",
    "    \n",
    "    # LLM inference time for cross-device scenario\n",
    "    print(\"\\nMeasuring LLM inference time...\")\n",
    "    llm_cross_time = time_llm_inference(call_tv_events, llm_tokenizer, llm_model, num_runs=1)\n",
    "    print(f\"LLM inference time for cross-device scenario: {llm_cross_time*1000:.2f} ms\")\n",
    "    \n",
    "    # Get LLM response for cross-device scenario\n",
    "    print(\"\\nGenerating LLM response...\")\n",
    "    llm_cross_response, _ = llm_inference(call_tv_events, llm_tokenizer, llm_model)\n",
    "    \n",
    "    # Display LLM recommendations\n",
    "    print(\"\\nLLM recommendations for cross-device scenario (raw output):\")\n",
    "    print(llm_cross_response)\n",
    "    \n",
    "    # Qualitative comparison\n",
    "    print(\"\\n--- Qualitative Comparison ---\")\n",
    "    print(\"\\nLLM approach:\")\n",
    "    print(\"- Generates natural language responses\")\n",
    "    print(\"- No training on specific smart home patterns required\")\n",
    "    print(\"- Much slower inference time\")\n",
    "    print(\"- Requires much more memory\")\n",
    "    \n",
    "    print(\"\\nLarge Event Model (LEM) approach:\")\n",
    "    print(\"- Much faster inference\")\n",
    "    print(\"- Returns specific actions from training data\")\n",
    "    print(\"- Requires specific training on smart home data\")\n",
    "    print(\"- More efficient for embedded systems\")\n",
    "    print(\"- Domain-specific knowledge incorporated through capability grouping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff8430",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "\n",
    "1. Load the Large Event Model (LEM) and required encoders\n",
    "2. Preprocess events and generate embeddings\n",
    "3. Find similar actions based on event sequence embeddings\n",
    "4. Measure inference time for different event sequences\n",
    "5. Create custom event sequences and get recommendations\n",
    "6. Compare our LEM with a general-purpose LLM\n",
    "\n",
    "The Large Event Model (LEM) effectively captures the semantic relationships between event sequences and can be used to generate recommendations for similar actions based on a user's recent activity patterns. The timing benchmarks provide insight into the model's performance characteristics for different sequence lengths.\n",
    "\n",
    "Compared to general-purpose LLMs, our specialized LEM offers significant advantages in terms of inference speed and efficiency, making it more suitable for real-time smart home applications where quick response times are critical. However, LLMs offer more flexibility in generating diverse responses without requiring domain-specific training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
